{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import cmocean\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(\"Using GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_and_compare_images(origninal_image, my_up_sample, plot=False, **kwargs):\n",
    "    '''\n",
    "    Process and compare the original image with the processed image.\n",
    "    \n",
    "    original_image: torch.Tensor, shape=(1, 2048, 2048)\n",
    "    my_up_sample: function, the function that upsample the image\n",
    "    plot: bool, whether to plot the images\n",
    "    **kwargs: additional arguments to pass to the upsample function\n",
    "    \n",
    "    return: processed_image, mean_difference\n",
    "    processed_image: torch.Tensor, shape=(1, 2048, 2048)\n",
    "    mean_difference: float, the mean difference between the original and processed image\n",
    "    '''\n",
    "    \n",
    "    # def downsample(image, size=(512, 512)):\n",
    "    #     return F.interpolate(image.unsqueeze(0), size=size, mode='bilinear', align_corners=False).squeeze(0)\n",
    "    def downsample(image, size=(512, 512)):\n",
    "        scale_factor = (image.shape[-2] // size[0], image.shape[-1] // size[1])\n",
    "        downsampled_image = F.avg_pool2d(image.unsqueeze(0), kernel_size=scale_factor).squeeze(0)\n",
    "        \n",
    "        return downsampled_image\n",
    "\n",
    "    def split_image(image, piece_size=(64, 64)):\n",
    "        pieces = []\n",
    "        for i in range(0, image.size(1), piece_size[0]):\n",
    "            for j in range(0, image.size(2), piece_size[1]):\n",
    "                pieces.append(image[:, i:i+piece_size[0], j:j+piece_size[1]])\n",
    "        return pieces\n",
    "\n",
    "    def stitch_image(pieces, image_size=(2048, 2048), piece_size=(256, 256)):\n",
    "        stitched_image = torch.zeros((pieces[0].size(0), *image_size))\n",
    "        idx = 0\n",
    "        for i in range(0, image_size[0], piece_size[0]):\n",
    "            for j in range(0, image_size[1], piece_size[1]):\n",
    "                stitched_image[:, i:i+piece_size[0], j:j+piece_size[1]] = pieces[idx]\n",
    "                idx += 1\n",
    "        return stitched_image\n",
    "\n",
    "    def compare_images(image1, image2):\n",
    "        difference = torch.abs(image1 - image2)\n",
    "        return difference\n",
    "\n",
    "    # Process the image\n",
    "    downsampled_image = downsample(origninal_image) # 1x2048x2048 -> 1x512x512\n",
    "    pieces = split_image(downsampled_image) # 1x512x512 -> 64x64x64\n",
    "    upsampled_pieces = [my_up_sample(piece) for piece in pieces] # 64 x (1x64x64 -> 1x256x256)\n",
    "    result_image = stitch_image(upsampled_pieces) # 64x256x256 -> 1x2048x2048\n",
    "    \n",
    "    # Compare the images\n",
    "    difference_image = compare_images(origninal_image, result_image)\n",
    "    mean_difference = difference_image.mean().item()\n",
    "\n",
    "    if plot:\n",
    "        plot_images(origninal_image, result_image, difference_image, mean_difference=mean_difference, **kwargs)\n",
    "\n",
    "    return result_image, mean_difference\n",
    "\n",
    "def plot_images(original, processed, difference, normalize=True, **kwargs):\n",
    "    '''\n",
    "    Plot the original image, processed image, difference image, and 1D power spectrum comparison.\n",
    "    \n",
    "    original, processed, difference: torch.Tensor, shape=(1, 2048, 2048)\n",
    "    normalize: bool, whether to normalize the images before plotting\n",
    "    **kwargs: additional arguments to pass to the plot function\n",
    "        save: bool, whether to save the figure\n",
    "        title: str, the title of the figure, if save is True then title should be h5 path\n",
    "    '''\n",
    "    \n",
    "    def radial_profile(data, center):\n",
    "        y, x = np.indices((data.shape))\n",
    "        r = np.sqrt((x - center[0])**2 + (y - center[1])**2)\n",
    "        r = r.astype(int)\n",
    "\n",
    "        tbin = np.bincount(r.ravel(), data.ravel())\n",
    "        nr = np.bincount(r.ravel())\n",
    "        radialprofile = tbin / nr\n",
    "        return radialprofile\n",
    "\n",
    "    def compute_1d_power_spectrum(frame):\n",
    "        # Compute the 2D Fourier transform\n",
    "        fft_frame = np.fft.fftshift(np.fft.fft2(frame))\n",
    "        \n",
    "        # Compute the power spectrum (magnitude squared)\n",
    "        power_spectrum = np.abs(fft_frame)**2\n",
    "        \n",
    "        # Compute the radial profile (1D power spectrum)\n",
    "        center = (power_spectrum.shape[1]//2, power_spectrum.shape[0]//2)\n",
    "        radial_prof = radial_profile(power_spectrum, center)\n",
    "        \n",
    "        return radial_prof\n",
    "    \n",
    "    if normalize:\n",
    "        def normalize(tensor):\n",
    "            return (tensor - tensor.min()) / (tensor.max() - tensor.min())\n",
    "        \n",
    "        original = normalize(original).permute(1, 2, 0).cpu().numpy()\n",
    "        processed = normalize(processed).permute(1, 2, 0).cpu().numpy()\n",
    "        difference = normalize(difference).permute(1, 2, 0).cpu().numpy()\n",
    "        \n",
    "    # Compute the 1D power spectrum for both images\n",
    "    img1 = np.squeeze(original)\n",
    "    img2 = np.squeeze(processed)\n",
    "    power_spectrum_1d_1 = compute_1d_power_spectrum(img1)\n",
    "    power_spectrum_1d_2 = compute_1d_power_spectrum(img2)\n",
    "\n",
    "    # Create the k values corresponding to the radial profile\n",
    "    k = np.arange(1, len(power_spectrum_1d_1) + 1)\n",
    "    comparison_line = 100000 * k**(-3.0) # 1/k^3 line for comparison\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(20, 6))\n",
    "\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.title('Original Image')\n",
    "    plt.imshow(original, cmap=cmocean.cm.balance)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.title('Processed Image')\n",
    "    plt.imshow(processed, cmap=cmocean.cm.balance)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.title('Difference Image')\n",
    "    plt.imshow(difference, cmap=cmocean.cm.balance)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.loglog(k, power_spectrum_1d_1, linewidth=3, label='Original Power Spectrum')\n",
    "    plt.loglog(k, power_spectrum_1d_2, label='Processed Power Spectrum')\n",
    "    plt.loglog(k, comparison_line, 'g--', lw=2, label=r'$k^{-3}$')\n",
    "    plt.title('1D Power Spectrum (Log-Log)')\n",
    "    plt.xlabel('Log(Radial Distance)')\n",
    "    plt.ylabel('Log(Power)')\n",
    "    plt.legend()\n",
    "    \n",
    "    title = (kwargs['title'] if 'title' in kwargs else 'Image Comparison') + (' (Mean Difference: {:.4f})'.format(kwargs['mean_difference']))\n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if kwargs.get('save', False):\n",
    "        filename = kwargs['title'].split('/')[-1].split('.')[0].lower() + '_comparison.png'\n",
    "        plt.savefig(filename, dpi=300)\n",
    "        print(f\"Figure saved as {filename}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.randn(1, 2048, 2048)  \n",
    "\n",
    "###! Put upsample diffusion forward here\n",
    "def my_up_sample(image):\n",
    "    result = F.interpolate(image.unsqueeze(0), size=(256, 256), mode='bilinear', align_corners=False).squeeze(0)\n",
    "    return result\n",
    "\n",
    "result_image, difference = process_and_compare_images(image, my_up_sample, plot=True, normalize=True)\n",
    "\n",
    "print(f\"Diff: {difference}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/data/rdl/NSTK/16000_2048_2048_seed_3407.h5'\n",
    "with h5py.File(file_path, 'r') as file:\n",
    "    image = torch.tensor(file['w'][0])\n",
    "    image = image.unsqueeze(0)\n",
    "    print(image.shape)\n",
    "    \n",
    "###! Put upsample diffusion forward here\n",
    "def my_up_sample(image):\n",
    "    return F.interpolate(image.unsqueeze(0), size=(256, 256), mode='bilinear', align_corners=False).squeeze(0)\n",
    "\n",
    "result_image, difference = process_and_compare_images(image, my_up_sample, plot=True, normalize=True, save=True, title=file_path)\n",
    "\n",
    "print(f\"Diff: {difference}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_energy_spectrum(img1, img2, label):\n",
    "\n",
    "    def radial_profile(data, center):\n",
    "        y, x = np.indices((data.shape))\n",
    "        r = np.sqrt((x - center[0])**2 + (y - center[1])**2)\n",
    "        r = r.astype(int)\n",
    "\n",
    "        tbin = np.bincount(r.ravel(), data.ravel())\n",
    "        nr = np.bincount(r.ravel())\n",
    "        radialprofile = tbin / nr\n",
    "        return radialprofile\n",
    "\n",
    "    def compute_1d_power_spectrum(frame):\n",
    "        # Compute the 2D Fourier transform\n",
    "        fft_frame = np.fft.fftshift(np.fft.fft2(frame))\n",
    "        \n",
    "        # Compute the power spectrum (magnitude squared)\n",
    "        power_spectrum = np.abs(fft_frame)**2\n",
    "        \n",
    "        # Compute the radial profile (1D power spectrum)\n",
    "        center = (power_spectrum.shape[1]//2, power_spectrum.shape[0]//2)\n",
    "        radial_prof = radial_profile(power_spectrum, center)\n",
    "        \n",
    "        return radial_prof\n",
    "\n",
    "    # Create a figure with a 1x3 grid layout for the subplots (two images and one spectrum plot)\n",
    "    fig, axes = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "\n",
    "    # Compute the 1D power spectrum for both images\n",
    "    img1 = img1.squeeze().numpy()\n",
    "    img2 = img2.squeeze().numpy()\n",
    "    power_spectrum_1d_1 = compute_1d_power_spectrum(img1)\n",
    "    power_spectrum_1d_2 = compute_1d_power_spectrum(img2)\n",
    "\n",
    "    # Create the k values corresponding to the radial profile\n",
    "    k = np.arange(1, len(power_spectrum_1d_1) + 1)\n",
    "\n",
    "    # Define the comparison line: k^-3\n",
    "    comparison_line = 100000 * k**(-3.0) \n",
    "\n",
    "    # Plot the first image\n",
    "    ax1 = axes[0]\n",
    "    ax1.imshow(img1, cmap=cmocean.cm.balance)\n",
    "    ax1.set_title('Original Image')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    # Plot the second image\n",
    "    ax2 = axes[1]\n",
    "    ax2.imshow(img2, cmap=cmocean.cm.balance)\n",
    "    ax2.set_title('Processed Image')\n",
    "    ax2.axis('off')\n",
    "\n",
    "    # Plot both 1D power spectra on the same plot in log-log scale\n",
    "    ax3 = axes[2]\n",
    "    ax3.loglog(k, power_spectrum_1d_1, label='Original Power Spectrum')\n",
    "    ax3.loglog(k, power_spectrum_1d_2, label='Processed Power Spectrum')\n",
    "    ax3.loglog(k, comparison_line, 'g--', lw=2, label=r'$k^{-3}$')\n",
    "    ax3.set_title('1D Power Spectrum (Log-Log)')\n",
    "    ax3.set_xlabel('Log(Radial Distance)')\n",
    "    ax3.set_ylabel('Log(Power)')\n",
    "    ax3.legend()\n",
    "\n",
    "    # Add a figure title with the label provided\n",
    "    fig.suptitle(f'Energy Spectrum Analysis: {label}', fontsize=14)\n",
    "\n",
    "    # Adjust layout to prevent overlapping\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_energy_spectrum(image, result_image, 'Original vs. Processed Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from unet import UNet\n",
    "from diffusion_model import GaussianDiffusionModel\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch_ema import ExponentialMovingAverage\n",
    "from tqdm import tqdm\n",
    "from plotting import plot_samples\n",
    "import h5py\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import cmocean\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw,ImageFont\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"os.environ['CUDA_VISIBLE_DEVICES']: {os.environ['CUDA_VISIBLE_DEVICES']}\")\n",
    "\n",
    "unet_model,lowres_head,future_head = UNet(image_size=256, in_channels=1, out_channels=1, \n",
    "                                            base_width=64,\n",
    "                                            num_pred_steps=3,\n",
    "                                            Reynolds_number=True)\n",
    "\n",
    "model = GaussianDiffusionModel(base_model=unet_model.cuda(),\n",
    "                                lowres_model = lowres_head.cuda(),\n",
    "                                forecast_model = future_head.cuda(),\n",
    "                                betas=(1e-4, 0.02),\n",
    "                                n_T=10, \n",
    "                                prediction_type = 'v', \n",
    "                                sampler = 'ddim')\n",
    "\n",
    "\n",
    "checkpoint_path = '/data/rdl/NSTK/checkpoint_ddim_v_multinode_64.pt'\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "#optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "model.base_model.load_state_dict(checkpoint[\"basemodel\"])\n",
    "model.lowres_model.load_state_dict(checkpoint[\"lowres_model\"])\n",
    "model.forecast_model.load_state_dict(checkpoint[\"forecast_model\"])\n",
    "\n",
    "ema = ExponentialMovingAverage(model.parameters(),decay=0.999)\n",
    "ema.load_state_dict(checkpoint[\"ema\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model\n",
    "ema = ema\n",
    "Reynolds_number = torch.tensor([16000.0]).to('cuda')\n",
    "image = torch.randn(1, 64, 64)  \n",
    "\n",
    "def generate_single_sample(image):\n",
    "    global model\n",
    "    global ema\n",
    "    global Reynolds_number\n",
    "    model.eval()\n",
    "    image = image.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        with ema.average_parameters():\n",
    "            image = image.to('cuda')\n",
    "            Reynolds_number = Reynolds_number.to('cuda')\n",
    "            \n",
    "            cond = image.to('cuda')\n",
    "            predictions = model.sample(cond.shape[0], \n",
    "                                        (1, 256, 256),\n",
    "                                        cond, None, Reynolds_number,'cuda',superres=True)\n",
    "            prediction = predictions[0, 0].cpu().numpy()        \n",
    "            prediction = torch.from_numpy(prediction).unsqueeze(0)                \n",
    "            \n",
    "            return prediction\n",
    "\n",
    "print(image.shape)\n",
    "pred = generate_single_sample(image)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(file_path, **kwargs):\n",
    "    match = re.search(r'/(\\d+)_', file_path)\n",
    "    re_number = int(match.group(1)) / 40000.0\n",
    "    Reynolds_number = torch.tensor([re_number]).to('cuda')\n",
    "\n",
    "    with h5py.File(file_path, 'r') as file:\n",
    "        image = torch.tensor(file['w'][0])\n",
    "        image = image.unsqueeze(0)\n",
    "\n",
    "    print(f\"Processing file: {file_path}, Re = {Reynolds_number.item():.3f}\")\n",
    "    result_image, difference = process_and_compare_images(image, generate_single_sample, plot=True, normalize=True, **kwargs)\n",
    "\n",
    "    print(f\"Diff: {difference}\")\n",
    "    return re_number, difference\n",
    "    \n",
    "file_path = file_path = '/data/rdl/NSTK/16000_2048_2048_seed_3407.h5'\n",
    "main(file_path, title='Test Run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = ['1000_2048_2048_seed_3407.h5', '32000_2048_2048_seed_987.h5', '600_2048_2048_seed_3407.h5', \n",
    "              '16000_2048_2048_seed_3407.h5', '8000_2048_2048_seed_3407.h5', '16000_2048_2048_seed_2150.h5', \n",
    "              '32000_2048_2048_seed_2150.h5', '8000_2048_2048_seed_2150.h5', '8000_2048_2048_seed_1000.h5', \n",
    "              '1000_2048_2048_seed_2150.h5', '12000_2048_2048_seed_1000.h5', '12000_2048_2048_seed_3407.h5', \n",
    "              '12000_2048_2048_seed_2150.h5', '4000_2048_2048_seed_2150.h5', '2000_2048_2048_seed_2150.h5', \n",
    "              '4000_2048_2048_seed_3407.h5', '2000_2048_2048_seed_3407.h5', '6000_2048_2048_seed_2150.h5', \n",
    "              '6000_2048_2048_seed_3407.h5', '24000_2048_2048_seed_2150.h5', '24000_2048_2048_seed_3407.h5']\n",
    "file_paths.sort()\n",
    "\n",
    "results = []\n",
    "for file_path in file_paths:\n",
    "    file_path = '/data/rdl/NSTK/' + file_path\n",
    "    re_number, difference = main(file_path, title=file_path, save=True)\n",
    "    results.append((re_number*40000, difference))\n",
    "\n",
    "print(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort(key=lambda x: x[0])\n",
    "for pair in results:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
